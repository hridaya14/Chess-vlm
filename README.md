# â™Ÿï¸ Hikaru-Inspired Chess LLM  

<p align="center">
  <img src="https://img.shields.io/badge/model-unsloth%2FLFM2--350M-blue?style=flat-square" />
  <img src="https://img.shields.io/badge/UI-PyQt5-green?style=flat-square" />
  <img src="https://img.shields.io/badge/status-experimental-yellow?style=flat-square" />
</p>

---

## ğŸ“– Overview  

This project explores **fine-tuning a lightweight language model (unsloth/LFM2-350M)** to emulate the chess-playing style of **Grandmaster Hikaru Nakamura**.  

- The model is trained to generate **UCI-standard moves** for compatibility with chess engines.  
- A **PyQt5 chessboard UI** is included, allowing you to play directly against the fine-tuned model.  
- Since itâ€™s based on a **compact SLM**, it can run in **mobile apps or lightweight environments**.  
- The fine-tuning pipeline leverages **LoRA adapters** for efficient training, with **wandb** integration for experiment tracking, and **Modal** for scalable deployment/monitoring.  

---

## âœ¨ Features  

- ğŸ¯ Fine-tuned on Hikaru Nakamuraâ€™s PGN games.  
- â™Ÿï¸ Generates valid **UCI chess moves**.  
- ğŸ–¥ï¸ Interactive **PyQt5 Chessboard UI**.  
- ğŸ“± Deployable in **mobile or desktop apps**.  
- ğŸ”§ Modular design: fine-tuning logic is separate (`slm/`), app runs independently (`app/`).  
- âš¡ LoRA-based fine-tuning for lightweight and efficient adaptation.  
- ğŸ“Š Experiment logging & monitoring with **wandb**.  
- â˜ï¸ Scalable training/inference via **Modal**.  

---

## âš™ï¸ Project Structure  

```
â”œâ”€â”€ app/                     # PyQt5 chessboard app
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ slm/                     # Datasets and finetuning scripts
â”‚   â”œâ”€â”€ data/raw/            # PGN dataset (Nakamura games)
â”‚   â”œâ”€â”€ scripts/             # Data + merge scripts
â”‚   â”œâ”€â”€ Makefile             # Training/evaluation automation
â”‚   â”œâ”€â”€ src/instruct         # Finetuning logic
â”‚   â””â”€â”€ ...
â”œâ”€â”€ assets/                  # Demo GIFs and visuals
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started  

### 1ï¸âƒ£ Clone the repo  
```bash
git clone https://github.com/hridaya14/Chess-vlm.git
cd Chess-vlm
```

### 2ï¸âƒ£ Install dependencies  

We recommend using [`uv`](https://github.com/astral-sh/uv) for package management.

```bash
uv sync
```

---

## ğŸ‹ï¸ Fine-Tuning Instructions  

All training steps are automated via the **Makefile** in the `slm/` directory.

### ğŸ“¥ Download Hikaruâ€™s games  

```bash
cd slm
make download-games
```

### ğŸ“ Generate instruction dataset  

```bash
make instruction-dataset
```

### ğŸ”§ Fine-tune the base model  

```bash
make fine-tuning
```

*(Default base model: `unsloth/LFM2-350M`)*  
> Uses **LoRA** adapters for efficient parameter-efficient fine-tuning.  
> Logs and metrics are automatically tracked via **wandb**.  

### ğŸ“Š Evaluate model checkpoint  

```bash
make evaluate
```

### ğŸ”— Merge final model  

```bash
make merge-model
```

---

## ğŸ® Running the Chess App  

Once the model is fine-tuned and merged:

```bash
cd app
uv run main.py
```

This will launch the **PyQt5 chessboard**, where you can play against the Hikaru-inspired LLM.

---

## ğŸ¥ Demo  

<p align="center">
  <img src="assets/demo.gif" width="600" alt="Demo of playing against the Hikaru LLM" />
</p>  

---

## ğŸ§‘â€ğŸ’» Development  

### Lint & Format  

```bash
cd slm
make lint
make lint-fix
make format
```

---

## ğŸ“Œ Notes  

* The project is experimental and may not always reflect Hikaruâ€™s exact style.  
* UCI move generation ensures compatibility with standard chess engines.  
* The app and model are modular â€” you can integrate the model into other frontends.  
* LoRA fine-tuning keeps training lightweight and fast.  
* Modal and wandb integration provide **scalable training** and **clear monitoring/logging**.  

---

## ğŸ“œ License  

MIT License â€“ feel free to use, modify, and share.  

---

## ğŸ™ Acknowledgements  

* [Hikaru Nakamura PGN Mentor Dataset](https://www.pgnmentor.com/players/Nakamura.zip)  
* [Unsloth LFM2-350M](https://huggingface.co/unsloth/LFM2-350M)  
* [wandb](https://wandb.ai/) â€“ experiment tracking  
* [Modal](https://modal.com/) â€“ serverless ML scaling  
* Chess community for inspiration â™Ÿï¸  
